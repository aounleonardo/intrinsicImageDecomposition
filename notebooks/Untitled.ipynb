{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAG = '/cvlabdata1/cvlab/datasets_aoun/flag_2/'\n",
    "IMAGES = 'images/'\n",
    "ALBEDOS = 'albedos/'\n",
    "SHADINGS = 'shadings/'\n",
    "SYNTHS = 'synths/'\n",
    "\n",
    "TYPE = 'b31_tl_tr-cotton/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_data_dir = FLAG + SYNTHS + TYPE\n",
    "validation_data_dir = FLAG + SHADINGS + TYPE\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    \n",
    "    \n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "\n",
    "#how to merge these 3?\n",
    "model.add(UpSampling2D(size=(2, 2)))\n",
    "model.add(UpSampling2D(size=(2, 2)))\n",
    "model.add(UpSampling2D(size=(2, 2)))\n",
    "### 8,8\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# add last layer width 1\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "        FLAG + IMAGES + TYPE,  # this is the target directory\n",
    "#         '/home/aoun/dl/',\n",
    "        target_size=(224, 224),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(nb_filters=32, nb_pool=2, nb_conv=3):\n",
    "    C_1 = 64\n",
    "    C_2 = 32\n",
    "    C_3 = 16\n",
    "    c = Convolution2D(C_1, nb_conv, nb_conv, border_mode='same', input_shape=input_shape)\n",
    "    mp = MaxPooling2D(pool_size=(nb_pool, nb_pool))\n",
    "    c2 = Convolution2D(C_2, nb_conv, nb_conv, border_mode='same', input_shape=input_shape)\n",
    "    mp2 = MaxPooling2D(pool_size=(nb_pool, nb_pool))\n",
    "    d = Dense(100)\n",
    "    encoder = get_encoder(c, c2, d, mp, mp2)\n",
    "    decoder = get_decoder(C_1, C_2, C_3, c, c2, d, mp, mp2, nb_pool)\n",
    "\n",
    "    graph = Graph()\n",
    "    graph.add_input(name='input', input_shape=input_shape)\n",
    "    graph.add_node(encoder, name='encoder', input='input')\n",
    "    graph.add_node(decoder, name='decoder', input='encoder')\n",
    "    graph.add_output(name='autoencoder_feedback', input='decoder')\n",
    "    graph.compile('rmsprop', {'autoencoder_feedback': 'mean_squared_error'})\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "\n",
    "def get_decoder(C_1, C_2, C_3, c, c2, d, mp, mp2, nb_pool):\n",
    "    decoder = models.Sequential()\n",
    "\n",
    "    decoder.add(DependentDense(d.input_shape[1], d, input_shape=(d.output_shape[1],)))\n",
    "    decoder.add(Activation('tanh'))\n",
    "    decoder.add(Reshape((C_2, 8, 8)))\n",
    "    # ====================================================\n",
    "    # decoder.add(DePool2D(mp3, size=(nb_pool, nb_pool)))\n",
    "    # decoder.add(Deconvolution2D(c3, nb_out_channels=C_2, border_mode='same'))\n",
    "    # decoder.add(Activation('tanh'))\n",
    "    # ====================================================\n",
    "    decoder.add(UpSampling2D(mp2, size=(nb_pool, nb_pool)))\n",
    "    decoder.add(Convolution2D(c2, nb_out_channels=C_1, border_mode='same'))\n",
    "    decoder.add(Activation('tanh'))\n",
    "    # ====================================================\n",
    "    # Changed from Deconvolution2D to Convolution2D (here and up)\n",
    "    decoder.add(UpSampling2D(mp, size=(nb_pool, nb_pool)))\n",
    "    decoder.add(Convolution2D(c, nb_out_channels=3, border_mode='same'))\n",
    "    decoder.add(Activation('tanh'))\n",
    "    # ====================================================\n",
    "    return decoder\n",
    "\n",
    "\n",
    "def get_encoder(c, c2, d, mp, mp2):\n",
    "    encoder = models.Sequential()\n",
    "    # ====================================================\n",
    "    encoder.add(c)\n",
    "    encoder.add(Activation('tanh'))\n",
    "    encoder.add(mp)\n",
    "    # ====================================================\n",
    "    encoder.add(Dropout(0.25))\n",
    "    # ====================================================\n",
    "    encoder.add(c2)\n",
    "    encoder.add(Activation('tanh'))\n",
    "    encoder.add(mp2)\n",
    "    # ====================================================\n",
    "    # model.add(c3)\n",
    "    # model.add(Activation('tanh'))\n",
    "    # model.add(mp3)\n",
    "    # ====================================================\n",
    "    encoder.add(Dropout(0.25))\n",
    "    # ====================================================\n",
    "    encoder.add(Flatten())\n",
    "    encoder.add(d)\n",
    "    encoder.add(Activation('tanh'))\n",
    "    return encoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
